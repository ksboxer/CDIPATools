% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/predictiveperformancemetrics.R
\name{auc_roc}
\alias{auc_roc}
\title{Calculates area under the curve (AUC) for the receiver-operator cureve (ROC) for continious predictions, and actual predictions
KP: The summary above and below don't match.
This function takes the predictions of a model, (can be either binary 0 or 1, or continous numeric [0,1]) and
calculates the ROC curve, and then computes the AUC given the predicted values and actual values}
\usage{
auc_roc(predictions, outcomes)
}
\arguments{
\item{predictions}{list of numerics,  predicted values}

\item{outcomes}{list of numerics, actual values/outcomes}
}
\value{
numeric, returns AUC ROC value
}
\description{
Calculates area under the curve (AUC) for the receiver-operator cureve (ROC) for continious predictions, and actual predictions
KP: The summary above and below don't match.
This function takes the predictions of a model, (can be either binary 0 or 1, or continous numeric [0,1]) and
calculates the ROC curve, and then computes the AUC given the predicted values and actual values
}
\examples{
auc_roc(predictions = FakePredictionResults$est.risk.score,
outcomes = FakePredictionResults$true.risk.bin)
}
