% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/metrics.R
\name{auc_pr}
\alias{auc_pr}
\title{Calculates AUC Precision Recall  for continious predictions, and autual predictions}
\usage{
auc_pr(predictions, labels)
}
\arguments{
\item{predictions}{list of numerics,  predicted values}

\item{labels}{list of numerics, actual values/outcomes}
}
\value{
numeric, returns AUC precision recall value
}
\description{
This function takes the predictions of a model, (can be either binary 0 or 1, or continous numeric [0,1]) and
calculates the precision recall curve, and then gets the auc under the curve given the predicted values and actual values
Notes : baseline is ~.35, and perfect is 1
}
