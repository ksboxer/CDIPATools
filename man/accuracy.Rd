% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/metrics.R
\name{accuracy}
\alias{accuracy}
\title{Calculate the Accuracy for predictions}
\usage{
accuracy(predictions, labels, threshold)
}
\arguments{
\item{predictions}{list of numerics,  predicted values}

\item{labels}{list of numerics, actual values/outcomes}

\item{threshold}{numeric, value between 0 - 1 to cut  predictions that are continous within binary 0s and 1s}
}
\value{
numeric, returns accuracy value
}
\description{
This function takes the predictions of a model, (can be either binary 0 or 1, or continous numeric [0,1]) and
calculates the accuracy based on the predictions.  Given that predictions need to binary for the accuracy calculates
you need to pass in a threshold to but the predictions off.  If the predictions are already binary, then pass in .5
Note: if there are imbalanced positives and negatives this metric might not be that useful
}
